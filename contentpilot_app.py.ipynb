{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03068475-d8ec-413c-8acd-9ba03c25598a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting contentpilot_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile contentpilot_app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utility: clean column names\n",
    "\n",
    "import unicodedata\n",
    "import re as _re\n",
    "\n",
    "def clean_col(col):\n",
    "  \n",
    "    col = unicodedata.normalize(\"NFKD\", col)\n",
    "    col = col.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    " \n",
    "    col = col.replace(\"\\u00a0\", \" \")\n",
    "\n",
    "    \n",
    "    col = col.strip().lower()\n",
    "\n",
    "    \n",
    "    col = col.replace(\"%\", \" pct\")\n",
    "    col = col.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    col = col.replace(\"/\", \" per \")\n",
    "\n",
    "   \n",
    "    col = _re.sub(r\"\\s+\", \"_\", col)\n",
    "\n",
    "    return col\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess YouTube dataset\n",
    "\n",
    "def preprocess_youtube_df(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_raw.copy()\n",
    "\n",
    "   \n",
    "    df.columns = [clean_col(c) for c in df.columns]\n",
    "\n",
    "  \n",
    "    if \"date\" not in df.columns:\n",
    "        raise ValueError(\"Could not find a 'Date' column in the uploaded file.\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    df = df[df[\"date\"].notna()].copy()\n",
    "\n",
    "   \n",
    "    df[\"year\"] = df[\"date\"].dt.year\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"day\"] = df[\"date\"].dt.day\n",
    "    df[\"dayofweek\"] = df[\"date\"].dt.dayofweek  # 0=Mon..6=Sun\n",
    "    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5, 6]).astype(int)\n",
    "\n",
    "    \n",
    "    percent_cols = [\n",
    "        \"impressions_click_through_rate_pct\",\n",
    "        \"likes_vs_dislikes_pct\",\n",
    "        \"average_percentage_viewed_pct\",\n",
    "    ]\n",
    "    for col in percent_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.replace(\"%\", \"\", regex=False)\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    \n",
    "    num_cols = [\n",
    "        \"average_views_per_viewer\",\n",
    "        \"unique_viewers\",\n",
    "        \"impressions\",\n",
    "        \"comments_added\",\n",
    "        \"shares\",\n",
    "        \"dislikes\",\n",
    "        \"subscribers_lost\",\n",
    "        \"subscribers_gained\",\n",
    "        \"likes\",\n",
    "        \"videos_published\",\n",
    "        \"videos_added\",\n",
    "        \"subscribers\",\n",
    "        \"views\",\n",
    "        \"watch_time_hours\",\n",
    "        \"average_view_duration\",\n",
    "        \"your_estimated_revenue_usd\",\n",
    "    ]\n",
    "    for col in num_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Train daily-views model\n",
    "\n",
    "def train_views_model(df: pd.DataFrame):\n",
    "    if \"views\" not in df.columns:\n",
    "        raise ValueError(\"Could not find 'views' column after cleaning.\")\n",
    "\n",
    "    data = df.dropna(subset=[\"views\"]).copy()\n",
    "\n",
    "    all_feature_candidates = [\n",
    "        \"impressions\",\n",
    "        \"impressions_click_through_rate_pct\",\n",
    "        \"videos_published\",\n",
    "        \"average_views_per_viewer\",\n",
    "        \"average_percentage_viewed_pct\",\n",
    "        \"watch_time_hours\",\n",
    "        \"subscribers\",\n",
    "        \"dayofweek\",\n",
    "        \"month\",\n",
    "        \"is_weekend\",\n",
    "    ]\n",
    "    feature_cols = [c for c in all_feature_candidates if c in data.columns]\n",
    "\n",
    "    X = data[feature_cols].fillna(0)\n",
    "    y = data[\"views\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    metrics = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "    return model, feature_cols, metrics, data\n",
    "\n",
    "\n",
    "\n",
    "# Weekly strategy helpers\n",
    "\n",
    "def suggest_youtube_posting_days(df, n_days=3):\n",
    "    dow_map = {0: \"Mon\", 1: \"Tue\", 2: \"Wed\", 3: \"Thu\", 4: \"Fri\", 5: \"Sat\", 6: \"Sun\"}\n",
    "    views_by_dow = df.groupby(\"dayofweek\")[\"views\"].mean().sort_values(ascending=False)\n",
    "    top_days_idx = views_by_dow.head(n_days).index.tolist()\n",
    "    top_days = [dow_map[i] for i in top_days_idx]\n",
    "    return views_by_dow, top_days\n",
    "\n",
    "\n",
    "def build_weekly_content_plan(best_days, videos_per_week=4):\n",
    "    all_days = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "    plan = {day: 0 for day in all_days}\n",
    "    i = 0\n",
    "    for _ in range(videos_per_week):\n",
    "        day = best_days[i % len(best_days)]\n",
    "        plan[day] += 1\n",
    "        i += 1\n",
    "    return plan\n",
    "\n",
    "\n",
    "\n",
    "# Title scoring + A/B optimizer\n",
    "\n",
    "power_phrases = [\n",
    "    \"how to\", \"guide\", \"tips\", \"mistakes\", \"secrets\",\n",
    "    \"strategy\", \"step by step\", \"tutorial\", \"for beginners\"\n",
    "]\n",
    "\n",
    "def score_title(title, main_keyword=None):\n",
    "    t = str(title).strip()\n",
    "    t_lower = t.lower()\n",
    "    score = 0\n",
    "\n",
    "    # length\n",
    "    length = len(t)\n",
    "    if 40 <= length <= 70:\n",
    "        score += 2\n",
    "    elif 25 <= length < 40 or 70 < length <= 90:\n",
    "        score += 1\n",
    "\n",
    "    # number\n",
    "    if re.search(r\"\\d\", t):\n",
    "        score += 1\n",
    "\n",
    "    # power phrase\n",
    "    if any(phrase in t_lower for phrase in power_phrases):\n",
    "        score += 1\n",
    "\n",
    "    # main keyword\n",
    "    if main_keyword and main_keyword.lower() in t_lower:\n",
    "        score += 2\n",
    "\n",
    "    return score\n",
    "    \n",
    "#Step 1 â€“ Add a helper function\n",
    "\n",
    "\n",
    "def explain_title(title, main_keyword=None):\n",
    "    \"\"\"Return human-readable reasons for a title's score.\"\"\"\n",
    "    reasons = []\n",
    "    t = str(title).strip()\n",
    "    t_lower = t.lower()\n",
    "    length = len(t)\n",
    "\n",
    "   \n",
    "    if 40 <= length <= 70:\n",
    "        reasons.append(\"Length is in the ideal range (~40â€“70 characters).\")\n",
    "    elif 25 <= length < 40 or 70 < length <= 90:\n",
    "        reasons.append(\"Length is acceptable but could be closer to 40â€“70 characters.\")\n",
    "    else:\n",
    "        reasons.append(\"Length is outside the ideal range; consider adjusting it.\")\n",
    "\n",
    "   \n",
    "    if re.search(r\"\\d\", t):\n",
    "        reasons.append(\"Contains a number, which usually attracts more clicks.\")\n",
    "\n",
    "    \n",
    "    used_phrases = [phrase for phrase in power_phrases if phrase in t_lower]\n",
    "    if used_phrases:\n",
    "        reasons.append(\n",
    "            \"Uses strong phrases like \" + \", \".join(f'\"{p}\"' for p in used_phrases) + \".\"\n",
    "        )\n",
    "    else:\n",
    "        reasons.append(\"Does not use any strong 'how to / tips / guide' type phrase.\")\n",
    "\n",
    "    \n",
    "    if main_keyword and main_keyword.lower() in t_lower:\n",
    "        reasons.append(f\"Includes the main keyword: '{main_keyword}'.\")\n",
    "    else:\n",
    "        if main_keyword:\n",
    "            reasons.append(f\"Does not include the main keyword '{main_keyword}'.\")\n",
    "        else:\n",
    "            reasons.append(\"No main keyword was specified for scoring.\")\n",
    "\n",
    "    return reasons\n",
    "    \n",
    "\n",
    "def compare_titles(title_a, title_b, main_keyword=None):\n",
    "    score_a = score_title(title_a, main_keyword)\n",
    "    score_b = score_title(title_b, main_keyword)\n",
    "\n",
    "    if score_a > score_b:\n",
    "        recommendation = \"A\"\n",
    "    elif score_b > score_a:\n",
    "        recommendation = \"B\"\n",
    "    else:\n",
    "        recommendation = \"Tie\"\n",
    "\n",
    "    return {\n",
    "        \"title_a\": {\"title\": title_a, \"score\": score_a},\n",
    "        \"title_b\": {\"title\": title_b, \"score\": score_b},\n",
    "        \"recommendation\": recommendation,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# STREAMLIT APP\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"ContentPilot AI â€“ YouTube Creator Agent\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "st.title(\"ðŸŽ¬ ContentPilot AI â€“ YouTube Creator Agent\")\n",
    "st.write(\n",
    "    \"Upload your daily YouTube analytics export and let the agent learn \"\n",
    "    \"what drives your views, suggest posting days, and score your titles.\"\n",
    ")\n",
    "\n",
    "\n",
    "st.sidebar.header(\"1ï¸âƒ£ Upload Data\")\n",
    "uploaded_file = st.sidebar.file_uploader(\n",
    "    \"Upload YouTube daily analytics CSV\",\n",
    "    type=[\"csv\"],\n",
    "    help=\"Export from YouTube Analytics as CSV (daily metrics).\"\n",
    ")\n",
    "\n",
    "st.sidebar.header(\"2ï¸âƒ£ Agent Settings\")\n",
    "target_videos_per_week = st.sidebar.slider(\n",
    "    \"Target videos per week\", min_value=1, max_value=10, value=4\n",
    ")\n",
    "main_keyword = st.sidebar.text_input(\n",
    "    \"Main keyword / niche (for title scoring):\",\n",
    "    value=\"youtube\"\n",
    ")\n",
    "\n",
    "st.sidebar.header(\"3ï¸âƒ£ Candidate Titles (Optional)\")\n",
    "title_a_input = st.sidebar.text_input(\n",
    "    \"Title A\", value=\"5 Mistakes New YouTubers Make (Avoid These!)\"\n",
    ")\n",
    "title_b_input = st.sidebar.text_input(\n",
    "    \"Title B\", value=\"YouTube Growth Guide for Beginners\"\n",
    ")\n",
    "\n",
    "if uploaded_file is None:\n",
    "    st.info(\"ðŸ‘† Upload a CSV in the sidebar to get started.\")\n",
    "    st.stop()\n",
    "\n",
    "# Load and preprocess\n",
    "try:\n",
    "    df_raw = pd.read_csv(uploaded_file)\n",
    "except Exception as e:\n",
    "    st.error(f\"Error reading CSV: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "try:\n",
    "    yt = preprocess_youtube_df(df_raw)\n",
    "except Exception as e:\n",
    "    st.error(f\"Error preprocessing data: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "st.success(\"âœ… Data loaded and preprocessed successfully.\")\n",
    "\n",
    "\n",
    "tab1, tab2, tab3 = st.tabs([\"ðŸ“Š Model & Drivers\", \"ðŸ—“ Strategy Planner\", \"ðŸ§  Title Optimizer\"])\n",
    "\n",
    "# ==============\n",
    "# Tab 1: Model & Drivers\n",
    "# ==============\n",
    "with tab1:\n",
    "    st.subheader(\"Daily Views Model â€“ Performance & Drivers\")\n",
    "\n",
    "    st.write(\"Sample of cleaned data:\")\n",
    "    st.dataframe(yt.head())\n",
    "\n",
    "    try:\n",
    "        model, feature_cols, metrics, data = train_views_model(yt)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error training model: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "    col_metric1, col_metric2, col_metric3 = st.columns(3)\n",
    "    col_metric1.metric(\"MAE (views)\", f\"{metrics['MAE']:,.0f}\")\n",
    "    col_metric2.metric(\"RMSE (views)\", f\"{metrics['RMSE']:,.0f}\")\n",
    "    col_metric3.metric(\"RÂ²\", f\"{metrics['R2']:.3f}\")\n",
    "\n",
    "    st.markdown(\n",
    "    f\"\"\"\n",
    "    On the test data, the model explains about **{metrics['R2']*100:.1f}%** of the variation \n",
    "    in daily views. On average, it is off by roughly **{metrics['MAE']:,.0f} views per day**, \n",
    "    which is reasonable for the scale of this channel.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "    st.markdown(\"**Features used in model:**\")\n",
    "    st.write(feature_cols)\n",
    "\n",
    "    # Feature importance\n",
    "    st.markdown(\"### Feature Importance â€“ What Drives Views?\")\n",
    "    feat_imp = pd.Series(\n",
    "        model.feature_importances_,\n",
    "        index=feature_cols\n",
    "    ).sort_values(ascending=False)\n",
    "\n",
    "    st.write(feat_imp.to_frame(\"importance\"))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    feat_imp.plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_title(\"Feature Importance â€“ Daily Views Model\")\n",
    "    ax.set_ylabel(\"Importance\")\n",
    "    plt.tight_layout()\n",
    "    st.pyplot(fig)\n",
    "\n",
    "    st.caption(\n",
    "        \"The higher the importance, the more that feature contributes to predicting daily views. \"\n",
    "        \"This explains *why* the channel performs the way it does.\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# ==============\n",
    "# Tab 2: Strategy Planner\n",
    "# ==============\n",
    "with tab2:\n",
    "    st.subheader(\"Weekly Strategy & Content Calendar\")\n",
    "\n",
    "    try:\n",
    "        views_by_dow, best_days = suggest_youtube_posting_days(data)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error computing views by day-of-week: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "    st.markdown(\"**Average views by day-of-week:**\")\n",
    "    st.write(views_by_dow)\n",
    "\n",
    "    fig2, ax2 = plt.subplots(figsize=(6, 4))\n",
    "    views_by_dow.plot(kind=\"bar\", ax=ax2)\n",
    "    ax2.set_title(\"Average Views by Day of Week (0=Mon)\")\n",
    "    ax2.set_ylabel(\"Average Views\")\n",
    "    plt.tight_layout()\n",
    "    st.pyplot(fig2)\n",
    "\n",
    "    st.markdown(f\"**Suggested best posting days:** {', '.join(best_days)}\")\n",
    "\n",
    "   \n",
    "dow_map = {0: \"Mon\", 1: \"Tue\", 2: \"Wed\", 3: \"Thu\", 4: \"Fri\", 5: \"Sat\", 6: \"Sun\"}\n",
    "\n",
    "best_day_idx = views_by_dow.idxmax()\n",
    "worst_day_idx = views_by_dow.idxmin()\n",
    "\n",
    "best_day_name = dow_map.get(best_day_idx, str(best_day_idx))\n",
    "worst_day_name = dow_map.get(worst_day_idx, str(worst_day_idx))\n",
    "\n",
    "best_avg = views_by_dow.max()\n",
    "worst_avg = views_by_dow.min()\n",
    "\n",
    "st.markdown(\n",
    "    f\"The **strongest day** is **{best_day_name}** with around **{best_avg:,.0f}** \"\n",
    "    f\"average views, while the **weakest day** is **{worst_day_name}** \"\n",
    "    f\"with about **{worst_avg:,.0f}** views.\"\n",
    ")\n",
    "\n",
    "\n",
    "if worst_avg > 0:\n",
    "    uplift_pct = (best_avg - worst_avg) / worst_avg * 100\n",
    "    st.markdown(\n",
    "        f\"Focusing more uploads on the strongest days instead of the weakest ones \"\n",
    "        f\"can improve average daily views by roughly **{uplift_pct:.1f}%**.\"\n",
    "    )\n",
    "\n",
    "    weekly_plan = build_weekly_content_plan(best_days, videos_per_week=target_videos_per_week)\n",
    "    st.markdown(f\"**Weekly content plan for {target_videos_per_week} videos/week:**\")\n",
    "    st.write(pd.DataFrame.from_dict(weekly_plan, orient=\"index\", columns=[\"videos_per_day\"]))\n",
    "\n",
    "    st.caption(\n",
    "        \"Strategy: Focus your uploads on the historically strongest days, and distribute your \"\n",
    "        f\"{target_videos_per_week} videos across them for maximum impact.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ==============\n",
    "# Tab 3: Title Optimizer\n",
    "# ==============\n",
    "with tab3:\n",
    "    st.subheader(\"Title Scoring & A/B Comparison (Prototype)\")\n",
    "\n",
    "    st.write(\n",
    "        \"This is a simple heuristic title-scoring module. It rewards titles that:\\n\"\n",
    "        \"- Have a good length (~40â€“70 characters)\\n\"\n",
    "        \"- Use numbers\\n\"\n",
    "        \"- Include power phrases like 'how to', 'guide', 'tips'\\n\"\n",
    "        \"- Contain your main keyword\"\n",
    "    )\n",
    "\n",
    "    if title_a_input or title_b_input:\n",
    "        res = compare_titles(title_a_input, title_b_input, main_keyword=main_keyword)\n",
    "\n",
    "        st.markdown(\"**Scores:**\")\n",
    "        st.write(pd.DataFrame({\n",
    "            \"Title\": [res[\"title_a\"][\"title\"], res[\"title_b\"][\"title\"]],\n",
    "            \"Score\": [res[\"title_a\"][\"score\"], res[\"title_b\"][\"score\"]],\n",
    "            \"Label\": [\"A\", \"B\"]\n",
    "        }))\n",
    "\n",
    "        if res[\"recommendation\"] == \"Tie\":\n",
    "            st.info(\"Both titles are scored equally. Try tweaking one of them (add a number / power word / keyword).\")\n",
    "        else:\n",
    "            st.success(f\"Recommended: **Title {res['recommendation']}** based on heuristic score.\")\n",
    "            \n",
    "         \n",
    "    st.markdown(\"### Why each title got its score\")\n",
    "\n",
    "    reasons_a = explain_title(title_a_input, main_keyword=main_keyword)\n",
    "    reasons_b = explain_title(title_b_input, main_keyword=main_keyword)\n",
    "\n",
    "    st.markdown(\"**Title A analysis:**\")\n",
    "    for r in reasons_a:\n",
    "        st.write(\"- \" + r)\n",
    "\n",
    "    st.markdown(\"**Title B analysis:**\")\n",
    "    for r in reasons_b:\n",
    "        st.write(\"- \" + r)\n",
    "\n",
    "\n",
    "    st.caption(\n",
    "        \"In future, this rule-based title scorer can be replaced with a model trained on real title + CTR data, \"\n",
    "        \"or combined with an LLM to actually generate and iterate titles.\"\n",
    "    )\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.caption(\n",
    "    \"Future Work: Extend this agent with a podcast completion model and LLM-based post assets \"\n",
    "    \"(titles, hooks, descriptions, thumbnail text), making ContentPilot AI a multi-format creator assistant.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6e5047-d037-4051-a928-246f878cb1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\dell'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a5c3e-203a-4f1d-a00e-f0812f2c77ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2124250-86db-4d48-8aaa-15dee749d57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
